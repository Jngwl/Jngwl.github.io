

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.ico">
  <link rel="icon" type="image/png" href="/img/favicon.ico">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="清风与归_G">
  <meta name="keywords" content="">
  <title>PyTorch常用代码段整理 - 清风与归_G</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.5.3/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      
        
          
          
          
        
        <link  rel="stylesheet" href="https://cdn.staticfile.org/prism/1.22.0/themes/prism-tomorrow.min.css" />
      
      
    
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"www.jngwl.top","root":"/","version":"1.8.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"copy_btn":true,"image_zoom":{"enable":true},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"ViwB1XmjsmmXpFx2gikUmM5V-gzGzoHsz","app_key":"7r6Y8CzBkl8MJwPNmCqSdLWW","server_url":"https://viwb1xmj.lc-cn-n1-shared.com"}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>清风与归_G</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('https://hexo-blog-1254804803.cos.ap-shanghai.myqcloud.com/img/20201121211851.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="PyTorch常用代码段整理">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-05-05 22:24" pubdate>
        2020年5月5日 晚上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      71
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">PyTorch常用代码段整理</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：2021年1月8日 晚上
                
              </p>
            
            <div class="markdown-body">
              <p>本文代码基于PyTorch 1.0版本，需要用到以下包</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> collections
<span class="token keyword">import</span> os
<span class="token keyword">import</span> shutil
<span class="token keyword">import</span> tqdm

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> PIL<span class="token punctuation">.</span>Image
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision</code></pre>
<h2 id="1-基础配置"><a href="#1-基础配置" class="headerlink" title="1. 基础配置"></a><strong>1. 基础配置</strong></h2><h5 id="检查PyTorch版本"><a href="#检查PyTorch版本" class="headerlink" title="检查PyTorch版本"></a><strong>检查PyTorch版本</strong></h5><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>__version__               <span class="token comment"># PyTorch version</span>
torch<span class="token punctuation">.</span>version<span class="token punctuation">.</span>cuda              <span class="token comment"># Corresponding CUDA version</span>
torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>version<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Corresponding cuDNN version</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>get_device_name<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>   <span class="token comment"># GPU type</span></code></pre>
<h5 id="更新PyTorch"><a href="#更新PyTorch" class="headerlink" title="更新PyTorch"></a><strong>更新PyTorch</strong></h5><p>PyTorch将被安装在anaconda3/lib/python3.7/site-packages/torch/目录下。</p>
<pre class="language-bash" data-language="bash"><code class="language-bash">conda update pytorch torchvision -c pytorch</code></pre>
<h5 id="固定随机种子"><a href="#固定随机种子" class="headerlink" title="固定随机种子"></a><strong>固定随机种子</strong></h5><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre>
<h5 id="指定程序运行在特定GPU卡上"><a href="#指定程序运行在特定GPU卡上" class="headerlink" title="指定程序运行在特定GPU卡上"></a><strong>指定程序运行在特定GPU卡上</strong></h5><p>在命令行指定环境变量</p>
<pre class="language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> python train.py</code></pre>
<p>或在代码中指定</p>
<pre class="language-python" data-language="python"><code class="language-python">os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'0,1'</span></code></pre>
<h5 id="判断是否有CUDA支持"><a href="#判断是否有CUDA支持" class="headerlink" title="判断是否有CUDA支持"></a><strong>判断是否有CUDA支持</strong></h5><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<h5 id="设置为cuDNN-benchmark模式"><a href="#设置为cuDNN-benchmark模式" class="headerlink" title="设置为cuDNN benchmark模式"></a><strong>设置为cuDNN benchmark模式</strong></h5><p>Benchmark模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。</p>
<pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span></code></pre>
<p>如果想要避免这种结果波动，设置</p>
<pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span></code></pre>
<h5 id="清除GPU存储"><a href="#清除GPU存储" class="headerlink" title="清除GPU存储"></a><strong>清除GPU存储</strong></h5><p>有时Control-C中止运行后GPU存储没有及时释放，需要手动清空。在PyTorch内部可以</p>
<pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p>或在命令行可以先使用ps找到程序的PID，再使用kill结束该进程</p>
<pre class="language-python" data-language="python"><code class="language-python">ps aux <span class="token operator">|</span> grep python
kill <span class="token operator">-</span><span class="token number">9</span> <span class="token punctuation">[</span>pid<span class="token punctuation">]</span></code></pre>
<p>或者直接重置没有被清空的GPU</p>
<pre class="language-python" data-language="python"><code class="language-python">nvidia<span class="token operator">-</span>smi <span class="token operator">-</span><span class="token operator">-</span>gpu<span class="token operator">-</span>reset <span class="token operator">-</span>i <span class="token punctuation">[</span>gpu_id<span class="token punctuation">]</span></code></pre>
<h2 id="2-张量处理"><a href="#2-张量处理" class="headerlink" title="2. 张量处理"></a><strong>2. 张量处理</strong></h2><h5 id="张量基本信息"><a href="#张量基本信息" class="headerlink" title="张量基本信息"></a><strong>张量基本信息</strong></h5><pre class="language-python" data-language="python"><code class="language-python">tensor<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># Data type</span>
tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># Shape of the tensor. It is a subclass of Python tuple</span>
tensor<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># Number of dimensions.</span></code></pre>
<h5 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a><strong>数据类型转换</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Set default tensor type. Float in PyTorch is much faster than double.</span>
torch<span class="token punctuation">.</span>set_default_tensor_type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span>

<span class="token comment"># Type convertions.</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<h5 id="torch-Tensor与np-ndarray转换"><a href="#torch-Tensor与np-ndarray转换" class="headerlink" title="torch.Tensor与np.ndarray转换"></a><strong>torch.Tensor与np.ndarray转换</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># torch.Tensor -> np.ndarray.</span>
ndarray <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># np.ndarray -> torch.Tensor.</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># If ndarray has negative stride</span></code></pre>
<h5 id="torch-Tensor与PIL-Image转换"><a href="#torch-Tensor与PIL-Image转换" class="headerlink" title="torch.Tensor与PIL.Image转换"></a><strong>torch.Tensor与PIL.Image转换</strong></h5><p>PyTorch中的张量默认采用N×D×H×W的顺序，并且数据范围在[0, 1]，需要进行转置和规范化。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># torch.Tensor -> PIL.Image.</span>
image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>tensor <span class="token operator">*</span> <span class="token number">255</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">255</span>
    <span class="token punctuation">)</span><span class="token punctuation">.</span>byte<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
image <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_pil_image<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>  <span class="token comment"># Equivalently way</span>

<span class="token comment"># PIL.Image -> torch.Tensor.</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>
tensor <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Equivalently way</span></code></pre>
<h5 id="np-ndarray与PIL-Image转换"><a href="#np-ndarray与PIL-Image转换" class="headerlink" title="np.ndarray与PIL.Image转换"></a><strong>np.ndarray与PIL.Image转换</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># np.ndarray -> PIL.Image.</span>
image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>astypde<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># PIL.Image -> np.ndarray.</span>
ndarray <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h5 id="从只包含一个元素的张量中提取值"><a href="#从只包含一个元素的张量中提取值" class="headerlink" title="从只包含一个元素的张量中提取值"></a><strong>从只包含一个元素的张量中提取值</strong></h5><p>这在训练时统计loss的变化过程中特别有用。否则这将累积计算图，使GPU存储占用量越来越大。</p>
<pre class="language-python" data-language="python"><code class="language-python">value <span class="token operator">=</span> tensor<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<h5 id="张量形变"><a href="#张量形变" class="headerlink" title="张量形变"></a><strong>张量形变</strong></h5><p>张量形变常常需要用于将卷积层特征输入全连接层的情形。相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。</p>
<pre class="language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> shape<span class="token punctuation">)</span></code></pre>
<h5 id="打乱顺序"><a href="#打乱顺序" class="headerlink" title="打乱顺序"></a><strong>打乱顺序</strong></h5><pre class="language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># Shuffle the first dimension</span></code></pre>
<h5 id="水平翻转"><a href="#水平翻转" class="headerlink" title="水平翻转"></a><strong>水平翻转</strong></h5><p>PyTorch不支持tensor[::-1]这样的负步长操作，水平翻转可以用张量索引实现。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Assume tensor has shape N*D*H*W.</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre>
<h5 id="复制张量"><a href="#复制张量" class="headerlink" title="复制张量"></a><strong>复制张量</strong></h5><p>有三种复制的方式，对应不同的需求。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Operation                 |  New/Shared memory | Still in computation graph |</span>
tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># |        New         |          Yes               |</span>
tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token comment"># |      Shared        |          No                |</span>
tensor<span class="token punctuation">.</span>detach<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># |        New         |          No                |</span></code></pre>
<h5 id="拼接张量"><a href="#拼接张量" class="headerlink" title="拼接张量"></a><strong>拼接张量</strong></h5><p>注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，而torch.stack会新增一维。例如当参数是3个10×5的张量，torch.cat的结果是30×5的张量，而torch.stack的结果是3×10×5的张量。</p>
<pre class="language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre>
<h5 id="将整数标记转换成独热（one-hot）编码"><a href="#将整数标记转换成独热（one-hot）编码" class="headerlink" title="将整数标记转换成独热（one-hot）编码"></a><strong>将整数标记转换成独热（one-hot）编码</strong></h5><p>PyTorch中的标记默认从0开始。</p>
<pre class="language-python" data-language="python"><code class="language-python">N <span class="token operator">=</span> tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
one_hot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> src<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h5 id="得到非零-零元素"><a href="#得到非零-零元素" class="headerlink" title="得到非零/零元素"></a><strong>得到非零/零元素</strong></h5><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>               <span class="token comment"># Index of non-zero elements</span>
torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>          <span class="token comment"># Index of zero elements</span>
torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>       <span class="token comment"># Number of non-zero elements</span>
torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># Number of zero elements</span></code></pre>
<h5 id="判断两个张量相等"><a href="#判断两个张量相等" class="headerlink" title="判断两个张量相等"></a><strong>判断两个张量相等</strong></h5><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>  <span class="token comment"># float tensor</span>
torch<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>     <span class="token comment"># int tensor</span></code></pre>
<h5 id="张量扩展"><a href="#张量扩展" class="headerlink" title="张量扩展"></a><strong>张量扩展</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Expand tensor of shape 64*512 to shape 64*512*7*7.</span>
torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span></code></pre>
<h5 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a><strong>矩阵乘法</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Matrix multiplication: (m*n) * (n*p) -> (m*p).</span>
result <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>

<span class="token comment"># Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p).</span>
result <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>

<span class="token comment"># Element-wise multiplication.</span>
result <span class="token operator">=</span> tensor1 <span class="token operator">*</span> tensor2</code></pre>
<h5 id="计算两组数据之间的两两欧式距离"><a href="#计算两组数据之间的两两欧式距离" class="headerlink" title="计算两组数据之间的两两欧式距离"></a><strong>计算两组数据之间的两两欧式距离</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># X1 is of shape m*d, X2 is of shape n*d.</span>
dist <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>X1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> X2<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h2 id="3-模型定义"><a href="#3-模型定义" class="headerlink" title="3. 模型定义"></a><strong>3. 模型定义</strong></h2><h5 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a><strong>卷积层</strong></h5><p>最常用的卷积层配置是</p>
<pre class="language-python" data-language="python"><code class="language-python">conv <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
conv <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre>
<p>如果卷积层配置比较复杂，不方便计算输出大小时，可以利用如下可视化工具辅助</p>
<p><a href="https://link.zhihu.com/?target=https%3A//ezyang.github.io/convolution-visualizer/index.html">Convolution Visualizerezyang.github.io</a></p>
<h5 id="GAP（Global-average-pooling）层"><a href="#GAP（Global-average-pooling）层" class="headerlink" title="GAP（Global average pooling）层"></a><strong>GAP（Global average pooling）层</strong></h5><pre class="language-python" data-language="python"><code class="language-python">gap <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre>
<h5 id="双线性汇合（bilinear-pooling）-1"><a href="#双线性汇合（bilinear-pooling）-1" class="headerlink" title="双线性汇合（bilinear pooling）[1]"></a><strong>双线性汇合（bilinear pooling）</strong><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59205847#ref_1">[1]</a></h5><pre class="language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> H <span class="token operator">*</span> W<span class="token punctuation">)</span>                        <span class="token comment"># Assume X has shape N*D*H*W</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>X<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>H <span class="token operator">*</span> W<span class="token punctuation">)</span>  <span class="token comment"># Bilinear pooling</span>
<span class="token keyword">assert</span> X<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> D<span class="token punctuation">)</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D <span class="token operator">*</span> D<span class="token punctuation">)</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>   <span class="token comment"># Signed-sqrt normalization</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>X<span class="token punctuation">)</span>                  <span class="token comment"># L2 normalization</span></code></pre>
<h5 id="多卡同步BN（Batch-normalization）"><a href="#多卡同步BN（Batch-normalization）" class="headerlink" title="多卡同步BN（Batch normalization）"></a><strong>多卡同步BN（Batch normalization）</strong></h5><p>当使用torch.nn.DataParallel将代码运行在多张GPU卡上时，PyTorch的BN层默认操作是各卡上数据独立地计算均值和标准差，同步BN使用所有卡上的数据一起计算BN层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。</p>
<p><a href="vacancy/Synchronized-BatchNorm-PyTorchgithub.com">vacancy/Synchronized-BatchNorm-PyTorchgithub.com</a></p>
<p>现在PyTorch官方已经支持同步BN操作</p>
<pre class="language-python" data-language="python"><code class="language-python">sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">05</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> 
                                 track_running_stats<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre>
<p>将已有网络的所有BN层改为同步BN层</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">convertBNtoSyncBN</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> process_group<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''Recursively replace all BN layers to SyncBN layer.

    Args:
        module[torch.nn.Module]. Network
    '''</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>batchnorm<span class="token punctuation">.</span>_BatchNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>module<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> module<span class="token punctuation">.</span>eps<span class="token punctuation">,</span> module<span class="token punctuation">.</span>momentum<span class="token punctuation">,</span> 
                                         module<span class="token punctuation">.</span>affine<span class="token punctuation">,</span> module<span class="token punctuation">.</span>track_running_stats<span class="token punctuation">,</span> process_group<span class="token punctuation">)</span>
        sync_bn<span class="token punctuation">.</span>running_mean <span class="token operator">=</span> module<span class="token punctuation">.</span>running_mean
        sync_bn<span class="token punctuation">.</span>running_var <span class="token operator">=</span> module<span class="token punctuation">.</span>running_var
        <span class="token keyword">if</span> module<span class="token punctuation">.</span>affine<span class="token punctuation">:</span>
            sync_bn<span class="token punctuation">.</span>weight <span class="token operator">=</span> module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
            sync_bn<span class="token punctuation">.</span>bias <span class="token operator">=</span> module<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> sync_bn
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> name<span class="token punctuation">,</span> child_module <span class="token keyword">in</span> module<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">setattr</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token operator">=</span> convert_syncbn_model<span class="token punctuation">(</span>child_module<span class="token punctuation">,</span> process_group<span class="token operator">=</span>process_group<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> module</code></pre>
<h5 id="类似BN滑动平均"><a href="#类似BN滑动平均" class="headerlink" title="类似BN滑动平均"></a><strong>类似BN滑动平均</strong></h5><p>如果要实现类似BN滑动平均的操作，在forward函数中要使用原地（inplace）操作给滑动平均赋值。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'running_mean'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        self<span class="token punctuation">.</span>running_mean <span class="token operator">+=</span> momentum <span class="token operator">*</span> <span class="token punctuation">(</span>current <span class="token operator">-</span> self<span class="token punctuation">.</span>running_mean<span class="token punctuation">)</span></code></pre>
<h5 id="计算模型整体参数量"><a href="#计算模型整体参数量" class="headerlink" title="计算模型整体参数量"></a><strong>计算模型整体参数量</strong></h5><pre class="language-python" data-language="python"><code class="language-python">num_parameters <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>numel<span class="token punctuation">(</span>parameter<span class="token punctuation">)</span> <span class="token keyword">for</span> parameter <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h5 id="类似Keras的model-summary-输出模型信息"><a href="#类似Keras的model-summary-输出模型信息" class="headerlink" title="类似Keras的model.summary()输出模型信息"></a><strong>类似Keras的model.summary()输出模型信息</strong></h5><p><a href="https://link.zhihu.com/?target=https%3A//github.com/sksq96/pytorch-summary">[sksq96/pytorch-summarygithub.com]</a></p>
<h5 id="模型权值初始化"><a href="#模型权值初始化" class="headerlink" title="模型权值初始化"></a><strong>模型权值初始化</strong></h5><p>注意model.modules()和model.children()的区别：model.modules()会迭代地遍历模型的所有子层，而model.children()只会遍历模型下的一层。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Common practise for initialization.</span>
<span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span>
                                      nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>

<span class="token comment"># Initialization with given tensor.</span>
layer<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span></code></pre>
<h5 id="部分层使用预训练模型"><a href="#部分层使用预训练模型" class="headerlink" title="部分层使用预训练模型"></a><strong>部分层使用预训练模型</strong></h5><p>注意如果保存的模型是torch.nn.DataParallel，则当前的模型也需要是torch.nn.DataParallel。torch.nn.DataParallel(model).module == model。</p>
<pre class="language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model,pth'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre>
<h5 id="将在GPU保存的模型加载到CPU"><a href="#将在GPU保存的模型加载到CPU" class="headerlink" title="将在GPU保存的模型加载到CPU"></a><strong>将在GPU保存的模型加载到CPU</strong></h5><pre class="language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model,pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h2 id="4-数据准备、特征提取与微调"><a href="#4-数据准备、特征提取与微调" class="headerlink" title="4. 数据准备、特征提取与微调"></a><strong>4. 数据准备、特征提取与微调</strong></h2><h5 id="图像分块打散（image-shuffle）-区域混淆机制（region-confusion-mechanism，RCM）-2"><a href="#图像分块打散（image-shuffle）-区域混淆机制（region-confusion-mechanism，RCM）-2" class="headerlink" title="图像分块打散（image shuffle）/区域混淆机制（region confusion mechanism，RCM）[2]"></a><strong>图像分块打散（image shuffle）/区域混淆机制（region confusion mechanism，RCM）</strong><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59205847#ref_2">[2]</a></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># X is torch.Tensor of size N*D*H*W.</span>
<span class="token comment"># Shuffle rows</span>
Q <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_blocks<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token operator">+</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token operator">=</span><span class="token operator">-</span>neighbour<span class="token punctuation">,</span> high<span class="token operator">=</span>neighbour<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>num_blocks<span class="token punctuation">,</span> num_blocks<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
Q <span class="token operator">=</span> torch<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> Q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>num_blocks<span class="token punctuation">,</span> num_blocks<span class="token punctuation">)</span>

X <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>row<span class="token punctuation">,</span> chunks<span class="token operator">=</span>num_blocks<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
     <span class="token keyword">for</span> row <span class="token keyword">in</span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> chunks<span class="token operator">=</span>num_blocks<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>X<span class="token punctuation">[</span>Q<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">]</span>
     <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token comment"># Shulle columns.</span>
Q <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>num_blocks<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
     <span class="token operator">+</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token operator">=</span><span class="token operator">-</span>neighbour<span class="token punctuation">,</span> high<span class="token operator">=</span>neighbour<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>num_blocks<span class="token punctuation">,</span> num_blocks<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
Q <span class="token operator">=</span> torch<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> Q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>num_blocks<span class="token punctuation">,</span> num_blocks<span class="token punctuation">)</span>
X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>Q<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">]</span>
     <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">]</span>

Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>row<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">for</span> row <span class="token keyword">in</span> X<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre>
<h5 id="得到视频数据基本信息"><a href="#得到视频数据基本信息" class="headerlink" title="得到视频数据基本信息"></a><strong>得到视频数据基本信息</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> cv2
video <span class="token operator">=</span> cv2<span class="token punctuation">.</span>VideoCapture<span class="token punctuation">(</span>mp4_path<span class="token punctuation">)</span>
height <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_HEIGHT<span class="token punctuation">)</span><span class="token punctuation">)</span>
width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_WIDTH<span class="token punctuation">)</span><span class="token punctuation">)</span>
num_frames <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_COUNT<span class="token punctuation">)</span><span class="token punctuation">)</span>
fps <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FPS<span class="token punctuation">)</span><span class="token punctuation">)</span>
video<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<h5 id="TSN每段（segment）采样一帧视频-3"><a href="#TSN每段（segment）采样一帧视频-3" class="headerlink" title="TSN每段（segment）采样一帧视频[3]"></a><strong>TSN每段（segment）采样一帧视频</strong><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59205847#ref_3">[3]</a></h5><pre class="language-python" data-language="python"><code class="language-python">K <span class="token operator">=</span> self<span class="token punctuation">.</span>_num_segments
<span class="token keyword">if</span> is_train<span class="token punctuation">:</span>
    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>
        <span class="token comment"># Random index for each segment.</span>
        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>
            high<span class="token operator">=</span>num_frames <span class="token operator">//</span> K<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>
            high<span class="token operator">=</span>num_frames<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>
            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> frame_indices<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>
        <span class="token comment"># Middle index for each segment.</span>
        frame_indices <span class="token operator">=</span> num_frames <span class="token operator">/</span> K <span class="token operator">//</span> <span class="token number">2</span>
        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>                              
            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">assert</span> frame_indices<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span>
<span class="token keyword">return</span> <span class="token punctuation">[</span>frame_indices<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre>
<h5 id="提取ImageNet预训练模型某层的卷积特征"><a href="#提取ImageNet预训练模型某层的卷积特征" class="headerlink" title="提取ImageNet预训练模型某层的卷积特征"></a><strong>提取ImageNet预训练模型某层的卷积特征</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># VGG-16 relu5-3 feature.</span>
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token comment"># VGG-16 pool5 feature.</span>
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features
<span class="token comment"># VGG-16 fc7 feature.</span>
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>classifier <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># ResNet GAP feature.</span>
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span>
    <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    conv_representation <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span></code></pre>
<h5 id="提取ImageNet预训练模型多层的卷积特征"><a href="#提取ImageNet预训练模型多层的卷积特征" class="headerlink" title="提取ImageNet预训练模型多层的卷积特征"></a><strong>提取ImageNet预训练模型多层的卷积特征</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FeatureExtractor</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Helper class to extract several convolution features from the given
    pre-trained model.

    Attributes:
        _model, torch.nn.Module.
        _layers_to_extract, list&lt;str> or set&lt;str>

    Example:
        >>> model = torchvision.models.resnet152(pretrained=True)
        >>> model = torch.nn.Sequential(collections.OrderedDict(
                list(model.named_children())[:-1]))
        >>> conv_representation = FeatureExtractor(
                pretrained_model=model,
                layers_to_extract=&#123;'layer1', 'layer2', 'layer3', 'layer4'&#125;)(image)
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_model<span class="token punctuation">,</span> layers_to_extract<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_model <span class="token operator">=</span> pretrained_model
        self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_layers_to_extract <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>layers_to_extract<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            conv_representation <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> name<span class="token punctuation">,</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
                <span class="token keyword">if</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>_layers_to_extract<span class="token punctuation">:</span>
                    conv_representation<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">return</span> conv_representation</code></pre>
<h5 id="其他预训练模型"><a href="#其他预训练模型" class="headerlink" title="其他预训练模型"></a><strong>其他预训练模型</strong></h5><p><a href="https://link.zhihu.com/?target=https%3A//github.com/Cadene/pretrained-models.pytorch">https://link.zhihu.com/?target=https%3A//github.com/Cadene/pretrained-models.pytorch</a></p>
<h5 id="微调全连接层"><a href="#微调全连接层" class="headerlink" title="微调全连接层"></a><strong>微调全连接层</strong></h5><pre class="language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>
model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>  <span class="token comment"># Replace the last fc layer</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span></code></pre>
<h5 id="以较大学习率微调全连接层，较小学习率微调卷积层"><a href="#以较大学习率微调全连接层，较小学习率微调卷积层" class="headerlink" title="以较大学习率微调全连接层，较小学习率微调卷积层"></a><strong>以较大学习率微调全连接层，较小学习率微调卷积层</strong></h5><pre class="language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
finetuned_parameters <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
conv_parameters <span class="token operator">=</span> <span class="token punctuation">(</span>p <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">id</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token keyword">not</span> <span class="token keyword">in</span> finetuned_parameters<span class="token punctuation">)</span>
parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> conv_parameters<span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> 
              <span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span></code></pre>
<h2 id="5-模型训练"><a href="#5-模型训练" class="headerlink" title="5. 模型训练"></a><strong>5. 模型训练</strong></h2><h5 id="常用训练和验证数据预处理"><a href="#常用训练和验证数据预处理" class="headerlink" title="常用训练和验证数据预处理"></a><strong>常用训练和验证数据预处理</strong></h5><p>其中ToTensor操作会将『PIL.Image或形状为H×W×D，数值范围为[0, 255]的np.ndarray』转换为『形状为D×H×W，数值范围为[0.0, 1.0]的torch.Tensor』。</p>
<pre class="language-python" data-language="python"><code class="language-python">train_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span>
                                             scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">]</span><span class="token punctuation">)</span>
 val_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h5 id="训练基本代码框架"><a href="#训练基本代码框架" class="headerlink" title="训练基本代码框架"></a><strong>训练基本代码框架</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> t <span class="token keyword">in</span> epoch<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">'Epoch %3d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        scores <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p><strong>标记平滑（label smoothing）</strong><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59205847#ref_4">[4]</a></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    N <span class="token operator">=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment"># C is the number of classes.</span>
    smoothed_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">,</span> fill_value<span class="token operator">=</span><span class="token number">0.1</span> <span class="token operator">/</span> <span class="token punctuation">(</span>C <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    smoothed_labels<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>

    score <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
    log_prob <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>log_prob <span class="token operator">*</span> smoothed_labels<span class="token punctuation">)</span> <span class="token operator">/</span> N
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p><strong>Mixup</strong><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59205847#ref_5">[5]</a></p>
<pre class="language-python" data-language="python"><code class="language-python">beta_distribution <span class="token operator">=</span> torch<span class="token punctuation">.</span>distributions<span class="token punctuation">.</span>beta<span class="token punctuation">.</span>Beta<span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span>
<span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># Mixup images.</span>
    lambda_ <span class="token operator">=</span> beta_distribution<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    index <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>images<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    mixed_images <span class="token operator">=</span> lambda_ <span class="token operator">*</span> images <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> images<span class="token punctuation">[</span>index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

    <span class="token comment"># Mixup loss.    </span>
    scores <span class="token operator">=</span> model<span class="token punctuation">(</span>mixed_images<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token punctuation">(</span>lambda_ <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> 
            <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> labels<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p><strong>L1正则化</strong></p>
<pre class="language-python" data-language="python"><code class="language-python">l1_regularization <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token comment"># Standard cross-entropy loss</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">+=</span> lambda_ <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p><strong>不对偏置项进行L2正则化/权值衰减（weight decay）</strong></p>
<pre class="language-python" data-language="python"><code class="language-python">bias_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>
others_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>
parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> bias_list<span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                
              <span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> others_list<span class="token punctuation">&#125;</span><span class="token punctuation">]</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span></code></pre>
<p><strong>梯度裁剪（gradient clipping）</strong></p>
<pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span></code></pre>
<p><strong>计算Softmax输出的准确率</strong></p>
<pre class="language-python" data-language="python"><code class="language-python">score <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
prediction <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
num_correct <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>prediction <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
accuruacy <span class="token operator">=</span> num_correct <span class="token operator">/</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre>
<p><strong>可视化模型前馈的计算图</strong></p>
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/szagoruyko/pytorchviz">https://link.zhihu.com/?target=https%3A//github.com/szagoruyko/pytorchviz</a></p>
<p><strong>可视化学习曲线</strong></p>
<p>有Facebook自己开发的Visdom和Tensorboard（仍处于实验阶段）两个选择。</p>
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/facebookresearch/visdom">[facebookresearch/visdomgithub.com]</a><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/tensorboard.html">torch.utils.tensorboard - PyTorch master documentationpytorch.org</a>)</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Example using Visdom.</span>
vis <span class="token operator">=</span> visdom<span class="token punctuation">.</span>Visdom<span class="token punctuation">(</span>env<span class="token operator">=</span><span class="token string">'Learning curve'</span><span class="token punctuation">,</span> use_incoming_socket<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> self<span class="token punctuation">.</span>_visdom<span class="token punctuation">.</span>check_connection<span class="token punctuation">(</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>_visdom<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
options <span class="token operator">=</span> collections<span class="token punctuation">.</span>namedtuple<span class="token punctuation">(</span><span class="token string">'Options'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">,</span> <span class="token string">'acc'</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>
    loss<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'xlabel'</span><span class="token punctuation">:</span> <span class="token string">'Epoch'</span><span class="token punctuation">,</span> <span class="token string">'ylabel'</span><span class="token punctuation">:</span> <span class="token string">'Loss'</span><span class="token punctuation">,</span> <span class="token string">'showlegend'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    acc<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'xlabel'</span><span class="token punctuation">:</span> <span class="token string">'Epoch'</span><span class="token punctuation">,</span> <span class="token string">'ylabel'</span><span class="token punctuation">:</span> <span class="token string">'Accuracy'</span><span class="token punctuation">,</span> <span class="token string">'showlegend'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    lr<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'xlabel'</span><span class="token punctuation">:</span> <span class="token string">'Epoch'</span><span class="token punctuation">,</span> <span class="token string">'ylabel'</span><span class="token punctuation">:</span> <span class="token string">'Learning rate'</span><span class="token punctuation">,</span> <span class="token string">'showlegend'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> t <span class="token keyword">in</span> epoch<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tran<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
    vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>X<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>train_loss<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             name<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'Loss'</span><span class="token punctuation">,</span> update<span class="token operator">=</span><span class="token string">'append'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span>options<span class="token punctuation">.</span>loss<span class="token punctuation">)</span>
    vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>X<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>val_loss<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             name<span class="token operator">=</span><span class="token string">'val'</span><span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'Loss'</span><span class="token punctuation">,</span> update<span class="token operator">=</span><span class="token string">'append'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span>options<span class="token punctuation">.</span>loss<span class="token punctuation">)</span>
    vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>X<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>train_acc<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             name<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'Accuracy'</span><span class="token punctuation">,</span> update<span class="token operator">=</span><span class="token string">'append'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span>options<span class="token punctuation">.</span>acc<span class="token punctuation">)</span>
    vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>X<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>val_acc<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             name<span class="token operator">=</span><span class="token string">'val'</span><span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'Accuracy'</span><span class="token punctuation">,</span> update<span class="token operator">=</span><span class="token string">'append'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span>options<span class="token punctuation">.</span>acc<span class="token punctuation">)</span>
    vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>X<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>lr<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             win<span class="token operator">=</span><span class="token string">'Learning rate'</span><span class="token punctuation">,</span> update<span class="token operator">=</span><span class="token string">'append'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span>options<span class="token punctuation">.</span>lr<span class="token punctuation">)</span></code></pre>
<p><strong>得到当前学习率</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># If there is one global learning rate (which is the common case).</span>
lr <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span>

<span class="token comment"># If there are multiple learning rates for different layers.</span>
all_lr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>
    all_lr<span class="token punctuation">.</span>append<span class="token punctuation">(</span>param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p><strong>学习率衰减</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Reduce learning rate when validation accuarcy plateau.</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ReduceLROnPlateau<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span> val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span>

<span class="token comment"># Cosine annealing learning rate.</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> T_max<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span>
<span class="token comment"># Reduce learning rate by 10 at given epochs.</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>MultiStepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> milestones<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    
    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span> val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>

<span class="token comment"># Learning rate warmup by 10 epochs.</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span><span class="token keyword">lambda</span> t<span class="token punctuation">:</span> t <span class="token operator">/</span> <span class="token number">10</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span> val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span></code></pre>
<p><strong>保存与加载断点</strong></p>
<p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Save checkpoint.</span>
is_best <span class="token operator">=</span> current_acc <span class="token operator">></span> best_acc
best_acc <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>best_acc<span class="token punctuation">,</span> current_acc<span class="token punctuation">)</span>
checkpoint <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">'best_acc'</span><span class="token punctuation">:</span> best_acc<span class="token punctuation">,</span>    
    <span class="token string">'epoch'</span><span class="token punctuation">:</span> t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
    <span class="token string">'model'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span>
model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> model_path<span class="token punctuation">)</span>
<span class="token keyword">if</span> is_best<span class="token punctuation">:</span>
    shutil<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">,</span> model_path<span class="token punctuation">)</span>

<span class="token comment"># Load checkpoint.</span>
<span class="token keyword">if</span> resume<span class="token punctuation">:</span>
    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">)</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
    best_acc <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'best_acc'</span><span class="token punctuation">]</span>
    start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Load checkpoint at epoch %d.'</span> <span class="token operator">%</span> start_epoch<span class="token punctuation">)</span></code></pre>
<p><strong>计算准确率、查准率（precision）、查全率（recall）</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># data['label'] and data['prediction'] are groundtruth label and prediction </span>
<span class="token comment"># for each image, respectively.</span>
accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token string">'prediction'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span>

<span class="token comment"># Compute recision and recall for each class.</span>
<span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tp <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">==</span> c<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'prediction'</span><span class="token punctuation">]</span> <span class="token operator">==</span> c<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    tp_fp <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'prediction'</span><span class="token punctuation">]</span> <span class="token operator">==</span> c<span class="token punctuation">)</span>
    tp_fn <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">==</span> c<span class="token punctuation">)</span>
    precision <span class="token operator">=</span> tp <span class="token operator">/</span> tp_fp <span class="token operator">*</span> <span class="token number">100</span>
    recall <span class="token operator">=</span> tp <span class="token operator">/</span> tp_fn <span class="token operator">*</span> <span class="token number">100</span></code></pre>
<h2 id="6-模型测试"><a href="#6-模型测试" class="headerlink" title="6. 模型测试"></a>6. 模型测试</h2><h5 id="计算每个类别的查准率（precision）、查全率（recall）、F1和总体指标"><a href="#计算每个类别的查准率（precision）、查全率（recall）、F1和总体指标" class="headerlink" title="计算每个类别的查准率（precision）、查全率（recall）、F1和总体指标"></a><strong>计算每个类别的查准率（precision）、查全率（recall）、F1和总体指标</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> sklearn<span class="token punctuation">.</span>metrics

all_label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
all_prediction <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
     <span class="token comment"># Data.</span>
     images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
     
     <span class="token comment"># Forward pass.</span>
     score <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
     
     <span class="token comment"># Save label and predictions.</span>
     prediction <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
     all_label<span class="token punctuation">.</span>append<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
     all_prediction<span class="token punctuation">.</span>append<span class="token punctuation">(</span>prediction<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Compute RP and confusion matrix.</span>
all_label <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>all_label<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>all_label<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span>
all_prediction <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>all_prediction<span class="token punctuation">)</span>
<span class="token keyword">assert</span> all_label<span class="token punctuation">.</span>shape <span class="token operator">==</span> all_prediction<span class="token punctuation">.</span>shape
micro_p<span class="token punctuation">,</span> micro_r<span class="token punctuation">,</span> micro_f1<span class="token punctuation">,</span> _ <span class="token operator">=</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>precision_recall_fscore_support<span class="token punctuation">(</span>
     all_label<span class="token punctuation">,</span> all_prediction<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token string">'micro'</span><span class="token punctuation">,</span> labels<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span>
class_p<span class="token punctuation">,</span> class_r<span class="token punctuation">,</span> class_f1<span class="token punctuation">,</span> class_occurence <span class="token operator">=</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>precision_recall_fscore_support<span class="token punctuation">(</span>
     all_label<span class="token punctuation">,</span> all_prediction<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> labels<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># Ci,j = #&#123;y=i and hat_y=j&#125;</span>
confusion_mat <span class="token operator">=</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>
     all_label<span class="token punctuation">,</span> all_prediction<span class="token punctuation">,</span> labels<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">assert</span> confusion_mat<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span></code></pre>
<h5 id="将各类结果写入电子表格"><a href="#将各类结果写入电子表格" class="headerlink" title="将各类结果写入电子表格"></a><strong>将各类结果写入电子表格</strong></h5><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> csv

<span class="token comment"># Write results onto disk.</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'wt'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
     f <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
     f<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Class'</span><span class="token punctuation">,</span> <span class="token string">'Label'</span><span class="token punctuation">,</span> <span class="token string">'# occurence'</span><span class="token punctuation">,</span> <span class="token string">'Precision'</span><span class="token punctuation">,</span> <span class="token string">'Recall'</span><span class="token punctuation">,</span> <span class="token string">'F1'</span><span class="token punctuation">,</span>
                 <span class="token string">'Confused class 1'</span><span class="token punctuation">,</span> <span class="token string">'Confused class 2'</span><span class="token punctuation">,</span> <span class="token string">'Confused class 3'</span><span class="token punctuation">,</span>
                 <span class="token string">'Confused 4'</span><span class="token punctuation">,</span> <span class="token string">'Confused class 5'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
     <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
         index <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>confusion_mat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>
         f<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span>
             label2class<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">,</span> class_occurence<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'%4.3f'</span> <span class="token operator">%</span> class_p<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token string">'%4.3f'</span> <span class="token operator">%</span> class_r<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'%4.3f'</span> <span class="token operator">%</span> class_f1<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token string">'%s:%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>label2class<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> confusion_mat<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 <span class="token string">'%s:%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>label2class<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> confusion_mat<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 <span class="token string">'%s:%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>label2class<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> confusion_mat<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 <span class="token string">'%s:%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>label2class<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> confusion_mat<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 <span class="token string">'%s:%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>label2class<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> confusion_mat<span class="token punctuation">[</span>index<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
         f<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'All'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>class_occurence<span class="token punctuation">)</span><span class="token punctuation">,</span> micro_p<span class="token punctuation">,</span> micro_r<span class="token punctuation">,</span> micro_f1<span class="token punctuation">,</span> 
                     <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<h2 id="7-PyTorch其他注意事项"><a href="#7-PyTorch其他注意事项" class="headerlink" title="7. PyTorch其他注意事项"></a><strong>7. PyTorch其他注意事项</strong></h2><h5 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h5><ul>
<li>建议有参数的层和汇合（pooling）层使用torch.nn模块定义，激活函数直接使用torch.nn.functional。torch.nn模块和torch.nn.functional的区别在于，torch.nn模块在计算时底层调用了torch.nn.functional，但torch.nn模块包括该层参数，还可以应对训练和测试两种网络状态。使用torch.nn.functional时要注意网络状态，如</li>
</ul>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span></code></pre>
<ul>
<li>model(x)前用model.train()和model.eval()切换网络状态。</li>
<li>不需要计算梯度的代码块用with torch.no<em>grad()包含起来。model.eval()和torch.no*</em>*grad()的区别在于，model.eval()是将网络切换为测试状态，例如BN和随机失活（dropout）在训练和测试阶段使用不同的计算方法。torch.no_grad()是关闭PyTorch张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行loss.backward()。</li>
<li>torch.nn.CrossEntropyLoss的输入不需要经过Softmax。torch.nn.CrossEntropyLoss等价于torch.nn.functional.log_softmax + torch.nn.NLLLoss。</li>
<li>loss.backward()前用optimizer.zero_grad()清除累积梯度。optimizer.zero_grad()和model.zero_grad()效果一样。</li>
</ul>
<h5 id="PyTorch性能与调试"><a href="#PyTorch性能与调试" class="headerlink" title="PyTorch性能与调试"></a>PyTorch性能与调试</h5><ul>
<li>torch.utils.data.DataLoader中尽量设置pin_memory=True，对特别小的数据集如MNIST设置pin_memory=False反而更快一些。num_workers的设置需要在实验中找到最快的取值。</li>
<li>用del及时删除不用的中间变量，节约GPU存储。</li>
<li>使用inplace操作可节约GPU存储，如</li>
</ul>
<pre class="language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre>
<p>此外，还可以通过torch.utils.checkpoint前向传播时只保留一部分中间结果来节约GPU存储使用，在反向传播时需要的内容从最近中间结果中计算得到。</p>
<ul>
<li>减少CPU和GPU之间的数据传输。例如如果你想知道一个epoch中每个mini-batch的loss和准确率，先将它们累积在GPU中等一个epoch结束之后一起传输回CPU会比每个mini-batch都进行一次GPU到CPU的传输更快。</li>
<li>使用半精度浮点数half()会有一定的速度提升，具体效率依赖于GPU型号。需要小心数值精度过低带来的稳定性问题。</li>
<li>时常使用assert tensor.size() == (N, D, H, W)作为调试手段，确保张量维度和你设想中一致。</li>
<li>除了标记y外，尽量少使用一维张量，使用n*1的二维张量代替，可以避免一些意想不到的一维张量计算结果。</li>
<li>统计代码各部分耗时</li>
</ul>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>profiler<span class="token punctuation">.</span>profile<span class="token punctuation">(</span>enabled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> use_cuda<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token keyword">as</span> profile<span class="token punctuation">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>profile<span class="token punctuation">)</span></code></pre>
<p>或者在命令行运行</p>
<pre class="language-python" data-language="python"><code class="language-python">python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>bottleneck main<span class="token punctuation">.</span>py</code></pre>
            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Python/">Python</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/PyTorch/">PyTorch</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/5cf99eb1/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Python 各类图像库的读取方式</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/5e67f605/">
                        <span class="hidden-mobile">Numpy.prod问题</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    Fluid.utils.waitElementVisible('vcomments', function() {
      Fluid.utils.createScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "ViwB1XmjsmmXpFx2gikUmM5V-gzGzoHsz",
          app_key: "7r6Y8CzBkl8MJwPNmCqSdLWW",
          placeholder: "来都来了，不说点什么吗⊙(・◇・)？",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: false,
          serverURLs: "",
        });
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the
    <a target="_blank" href="https://valine.js.org" rel="nofollow noopener noopener">comments powered by Valine.</a>
  </noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <i class="iconfont icon-tags-fill"></i>&nbsp;<a href="http://www.beian.miit.gov.cn/" target="_blank">鲁ICP备19062448号</a>&nbsp&nbsp;| &nbsp&nbsp <i class="iconfont icon-addrcard"></i>&nbsp; 2018~2022<a href="https://www.jngwl.top/" target="_blank"> 清风与归_G</a>&nbsp&nbsp;|&nbsp&nbsp;  <i class="iconfont icon-docker"></i> <a href="https://hexo.io/" target="_blank">&nbsp Hexo</a>&nbsp & &nbsp <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank">Fluid</a><br> 你的骄傲多半来自于自己的无知，共勉之

  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":200})
    NProgress.start()
    document.addEventListener('DOMContentLoaded', function() {
      window.NProgress && window.NProgress.inc();
    })
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.staticfile.org/jquery/3.5.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.5.3/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  
    
  



  <script  src="https://cdn.staticfile.org/tocbot/4.12.0/tocbot.min.js" ></script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>



  <script defer src="/js/leancloud.js" ></script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>












  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



</body>
</html>
